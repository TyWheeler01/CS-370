# CS-370
This project demonstrated a reinforcement learning agent trained that uses deep Q-learning to solve a maze and reach the treasure. The agent learns by interacting with its environment, then getting feedback in the form of rewards and penalties, and then developing a policy over time to best navigate the maze from any starting point. The files included the game environment, included python classes like TreasureMaze and GameExperience, and a Jupyter Notebook with placeholders. I was responsible for implementing the deep Q-learning algorithm, writing the training loop, defining the neural network, managing exploration versus exploitation behavior, and also fine tuning the agent’s performance by adjusting specific parameters. I also debugged and optimized the agent’s learning strategy by adjusting parameters such as epsilon decay, training epochs, and maximum step limits. These changes helped the agent find the most efficient policy and produce optimal results in the maze.

Computer scientists solve problems through logic, automation, and through using algorithms and data structures. This matters because these sorts of solutions affect so many aspects of our lives. Everything from search engines to AI agents, impact society, businesses, and individuals on a day to day basis. Everybody now relies on these technologies in some fashion, which have been thoroughly tested and optimized by computer scientists. I approach problems by breaking them into smaller and more manageable components. By understanding a system’s behavior and then iterating on solutions using experimentation and evidence, I am then able to tackle these problems piece by piece. In this project I had tested various training configurations, visualized the AI agent’s behavior, and used feedback loops to improve the agent’s performance over time. My ethical responsibilities are to design AI systems that behave reliably and fairly. This means ensuring that the agent makes optimal decisions without being biased in any way. Flawed data being fed to the agent or poor design choices can both lead to the result of bias in AI. Transparency, accuracy, and reproducibility are key to developing unbiased AI systems. This helps to benefit users and also uphold trust within any organization that uses these AI systems. 
