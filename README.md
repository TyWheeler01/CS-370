# CS-370
This project demonstrated a reinforcement learning agent trained using deep Q-learning to solve a maze and reach the treasure. The agent learns by interacting with its environment, receiving feedback in the form of rewards and penalties, and then developing a policy over time to best navigate the maze from any starting point. The files included the game environment, various python classes like TreasureMaze and GameExperience, and a Jupyter Notebook with function placeholders. I was responsible for implementing the deep Q-learning algorithm, writing the training loop, defining the neural network, managing exploration versus exploitation behavior, and fine tuning the agent’s performance by adjusting specific parameters. I also debugged and optimized the agent’s learning strategy by adjusting parameters such as epsilon decay, training epochs, and maximum step limits. These changes helped the agent converge on the most efficient policy and produce optimal results in the grid visualization.

Computer scientists solve problems through logic, automation, and the use of algorithms and data structures. This matters because these sorts of  scalable and intelligent solutions all the way from search engines to AI agents, impact society, businesses, and individuals on a day to day basis. Everybody relies on these technologies which have been thoroughly tested and optimized by computer scientists. I approach problems by breaking them into smaller, more manageable components. By understanding a system’s behavior entirely and then iterating on solutions using experimentation and evidence I am able to tackle these problems piece by piece. In this project I had tested various training configurations, visualized the AI agent’s behavior, and used feedback loops to improve the agent’s performance over time. My ethical responsibilities are to design AI systems that behave reliably and fairly. This means ensuring that the agent makes optimal decisions without being biased in any way. Flawed data being fed to the agent or poor design choices can both lead to the result of bias in AI. Transparency, accuracy, and reproducibility are key to developing unbiased AI systems. This helps to benefit users and also uphold trust within any organization that uses these AI systems. 
